criterion = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.0) 

    # Khởi tạo các tham số cho thuật toán GDA
    current_lr = 0.0005  # Learning rate khởi tạo
    sigma = 0.5
    kappa = 0.96

    best_val_loss = float('inf')
    patience_counter = 0
    max_patience = 3

    print("Start training CNN-LSTM with GDA Update...")

    # ==================== 3. Training Loop ====================
    for epoch in range(1, EPOCHS + 1):
        # --- Train ---
        model.train()
        train_loss = 0.0
        
        for batch_x, batch_y in train_loader:
            # Gọi hàm update thay thế cho quy trình chuẩn
            # Hàm này trả về LR mới (đã điều chỉnh) và loss của batch hiện tại
            current_lr, batch_loss_val = GDA_update(
                model, criterion, batch_x, batch_y, optimizer, 
                lambda_lr=current_lr, sigma=sigma, kappa=kappa
            )
            
            train_loss += batch_loss_val * batch_x.size(0)
        
        train_loss /= len(train_loader.dataset)
        
        # --- Validation ---
        model.eval()
        with torch.no_grad():
            val_preds = model(X_val_t)
            val_loss = criterion(val_preds, y_val_t).item()
        
        # In thông tin bao gồm cả Learning Rate hiện tại để theo dõi
        print(f"Epoch {epoch}/{EPOCHS} | LR: {current_lr:.6f} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}")

        # --- Early stopping + save best ---
        if val_loss < best_val_loss - 1e-6:
            best_val_loss = val_loss
            torch.save(model.state_dict(), os.path.join(MODEL_DIR, "best_coin_cnn_lstm.pth"))
            patience_counter = 0
            print(f"  → New best model saved! Val loss: {val_loss:.6f}")
        else:
            patience_counter += 1
            if patience_counter >= max_patience:
                print("Early stopping triggered.")
                break
